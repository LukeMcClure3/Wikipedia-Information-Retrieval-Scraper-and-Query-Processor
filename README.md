<h1>Wikipedia Information Retrieval Scraper and Query Processor</h1>

<h2>Abstract</h2>  
<p>For this project I set out to use articles from Wikipedia to build an information retrieval system that could process user queries and link to relevant Wikipedia pages using tools and frameworks such as Scrapy for crawling wikipedia articles, Scikit-Learn for building an Indexer, and Flask for processing user queries and displaying articles.</p>

<h2>Overview</h2>  
<p>My goal was to create a simple indexer and query processor that could be iterated on for future use. Different machine learning techniques could be implemented in the future for better or faster recommendations. 
</p>
<p>I split my code into 3 python files Crawler.py to crawl wikipedia and collect text and output a json file. indexer.py to take the json file and convert it to an inverted index of tf idf scores, and Processor.py to process queries using the inverted index and recommend articles. </p>
<h2>Design</h2>  
![image](design.png)
<p></p>
<h2>Architecture</h2>  
<p></p>
<h2>Operation</h2>  
<h2>Conclusion</h2>  
<h2>Data Sources</h2>  
<h2>Testing</h2>  
<h2>Source Code</h2>  
<h2>Bibliography</h2>  

